{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db9f1c30-df67-422d-aa58-55f11fd718f0",
   "metadata": {},
   "source": [
    "### Dataset Loading for Food101\n",
    "This cell defines the `get_data` function, which loads the Food101 dataset using torchvision, applies specified transformations, and creates subsets for training (160 samples per class) and testing (40 samples per class). The function returns the training subset, testing subset, and a list of class names. Ensure the `data_path` directory is valid and writable for downloading/storing the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2418fea9-5b2c-4cdc-af39-e542459e3fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import Food101\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Subset\n",
    "import pathlib\n",
    "from typing import Tuple, List\n",
    "\n",
    "def get_data(data_path: pathlib.Path, transform: transforms.Compose) -> Tuple[Subset, Subset, List[str]]:\n",
    "    \"\"\"\n",
    "    Load Food101 dataset and create subsets for training and testing.\n",
    "\n",
    "    Args:\n",
    "        data_path (Path): Path to store/load the dataset.\n",
    "        transform (transforms.Compose): Transformations to apply to the dataset.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[Subset, Subset, List[str]]: Training subset, testing subset, and list of class names.\n",
    "    \"\"\"\n",
    "    # Load training data\n",
    "    food101_train_data = Food101(\n",
    "        root=data_path / \"train\",\n",
    "        split='train',\n",
    "        transform=transform,\n",
    "        target_transform=None,\n",
    "        download=True\n",
    "    )\n",
    "\n",
    "    classes = food101_train_data.classes\n",
    "\n",
    "    # Create training subset (max 160 samples per class)\n",
    "    class_count = {}\n",
    "    indices = []\n",
    "    \n",
    "    for i, (_, label) in enumerate(food101_train_data):\n",
    "        if label not in class_count:\n",
    "            class_count[label] = 0\n",
    "\n",
    "        if class_count[label] < 160:\n",
    "            class_count[label] += 1\n",
    "            indices.append(i)\n",
    "\n",
    "    train_data = Subset(\n",
    "        dataset=food101_train_data, \n",
    "        indices=indices\n",
    "    )\n",
    "\n",
    "    # Load test data\n",
    "    food101_test_data = Food101(\n",
    "        root=data_path / \"test\",\n",
    "        split='test',\n",
    "        transform=transform,\n",
    "        target_transform=None,\n",
    "        download=True\n",
    "    )\n",
    "\n",
    "    # Create test subset (max 40 samples per class)\n",
    "    class_count = {}\n",
    "    indices = []\n",
    "\n",
    "    for i, (_, label) in enumerate(food101_test_data):\n",
    "        if label not in class_count:\n",
    "            class_count[label] = 0\n",
    "\n",
    "        if class_count[label] < 40:\n",
    "            class_count[label] += 1\n",
    "            indices.append(i)\n",
    "\n",
    "    test_data = Subset(\n",
    "        dataset=food101_test_data,\n",
    "        indices=indices\n",
    "    )\n",
    "        \n",
    "    return train_data, test_data, classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc8d291-b7cd-4fa3-bf31-82cbf8e078e6",
   "metadata": {},
   "source": [
    "### DataLoader Creation for Food101\n",
    "This cell defines the `get_dataloaders` function, which creates PyTorch DataLoader objects for training and testing subsets of the Food101 dataset. It uses a batch size of 32, disables multiprocessing (`num_workers=0`), enables shuffling for training, and disables it for testing. The function returns DataLoaders for both datasets, optimized with `pin_memory=True` for potential GPU usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8db960a2-0a24-4f64-a013-2660e57df599",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Subset\n",
    "from typing import Tuple\n",
    "\n",
    "def get_dataloaders(train_data: Subset, test_data: Subset) -> Tuple[DataLoader, DataLoader]:\n",
    "    \"\"\"\n",
    "    Create DataLoader objects for training and testing datasets.\n",
    "\n",
    "    Args:\n",
    "        train_data (Subset): Training dataset subset.\n",
    "        test_data (Subset): Testing dataset subset.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[DataLoader, DataLoader]: DataLoaders for training and testing datasets.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create dataloader for training dataset\n",
    "    train_dataloader = DataLoader(\n",
    "        dataset=train_data,\n",
    "        batch_size=32,\n",
    "        num_workers=0,\n",
    "        shuffle=True,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    # Create dataloader for testing dataset\n",
    "    test_dataloader = DataLoader(\n",
    "        dataset=test_data,\n",
    "        batch_size=32,\n",
    "        num_workers=0,\n",
    "        shuffle=False,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    return train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb3d223-91eb-4e04-985a-f8c06213b1a4",
   "metadata": {},
   "source": [
    "### Vision Transformer Model Setup\n",
    "This cell defines the `get_model` function, which loads a pre-trained Vision Transformer (ViT-B/16) model from torchvision, freezes its parameters, and replaces the classification head with a new linear layer for a specified number of output classes. The function returns the modified model, suitable for transfer learning. Ensure `out_features` matches the number of dataset classes (e.g., 101 for Food101)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13426191-9bf9-4db8-947d-01215b69b779",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import ViT_B_16_Weights, vit_b_16\n",
    "from torch import nn\n",
    "\n",
    "def get_model(out_features: int) -> nn.Module:\n",
    "    \"\"\"\n",
    "    Create a Vision Transformer (ViT-B/16) model with a modified classification head.\n",
    "\n",
    "    Args:\n",
    "        out_features (int): Number of output classes for the classification head.\n",
    "\n",
    "    Returns:\n",
    "        nn.Module: Modified ViT-B/16 model with frozen parameters and a new classification head.\n",
    "    \"\"\"\n",
    "    # Load pre-trained ViT-B/16 model\n",
    "    model = vit_b_16(weights=ViT_B_16_Weights.DEFAULT)\n",
    "\n",
    "    # Freeze all parameters\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Replace the classification head\n",
    "    model.heads.head = nn.Linear(\n",
    "        in_features=768,\n",
    "        out_features=out_features,\n",
    "        bias=True\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2a381c-6e8a-432d-ae24-8602ed407487",
   "metadata": {},
   "source": [
    "### ViT-B/16 Image Transformations\n",
    "This cell defines the `get_transform` function, which retrieves the default image transformation pipeline for the pre-trained Vision Transformer (ViT-B/16) model from torchvision. The transformations include resizing, center cropping, tensor conversion, and normalization suitable for ViT-B/16. The function returns a `transforms.Compose` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57b85ba2-343b-459f-994c-cd041bcffec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import ViT_B_16_Weights\n",
    "from torchvision import transforms\n",
    "\n",
    "def get_transform() -> transforms.Compose:\n",
    "    \"\"\"\n",
    "    Retrieve the default image transformations for the pre-trained ViT-B/16 model.\n",
    "\n",
    "    Returns:\n",
    "        transforms.Compose: A composed transform pipeline for ViT-B/16.\n",
    "    \"\"\"\n",
    "    return ViT_B_16_Weights.DEFAULT.transforms()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d89f006-b034-4785-87da-5fcdf1314c67",
   "metadata": {},
   "source": [
    "### Model Training and Evaluation\n",
    "This cell defines the `train_set` and `test_set` functions for training and evaluating a PyTorch model on a dataset. The `train_set` function runs one epoch of training, updating model parameters using the specified optimizer and loss function. The `test_set` function evaluates the model without gradient computation. Both functions calculate average loss and accuracy (in percentage) on the given device (e.g., CPU or GPU). Ensure the model, DataLoader, loss function, and device are compatible with the target dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e84cca5-00da-4ffc-80ca-1c249d8a90ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "from typing import Tuple\n",
    "\n",
    "def train_set(model: torch.nn.Module, \n",
    "              dataloader: torch.utils.data.DataLoader, \n",
    "              loss_fn: torch.nn.Module, \n",
    "              optimizer: torch.optim.Optimizer, \n",
    "              device: torch.device) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Train the model for one epoch on the training dataset.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The neural network model to train.\n",
    "        dataloader (torch.utils.data.DataLoader): DataLoader for the training dataset.\n",
    "        loss_fn (torch.nn.Module): Loss function for training.\n",
    "        optimizer (torch.optim.Optimizer): Optimizer for updating model parameters.\n",
    "        device (torch.device): Device to run the model on (e.g., 'cuda' or 'cpu').\n",
    "\n",
    "    Returns:\n",
    "        Tuple[float, float]: Average training loss and accuracy (in percentage) for the epoch.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    accuracy = 0.0\n",
    "\n",
    "    for X, y in dataloader:\n",
    "        # Move data to device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        y_logits = model(X)\n",
    "        loss = loss_fn(y_logits, y)\n",
    "        \n",
    "        # Compute predictions and accuracy\n",
    "        y_pred = torch.softmax(y_logits, dim=1).argmax(dim=1)\n",
    "        # Move to CPU and convert to NumPy for sklearn\n",
    "        y_cpu, y_pred_cpu = y.cpu().detach().numpy(), y_pred.cpu().detach().numpy()\n",
    "        accuracy += accuracy_score(y_cpu, y_pred_cpu)\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Compute average loss and accuracy\n",
    "    train_loss /= len(dataloader)\n",
    "    accuracy = (accuracy / len(dataloader)) * 100\n",
    "\n",
    "    return train_loss, accuracy\n",
    "\n",
    "\n",
    "def test_set(model: torch.nn.Module, \n",
    "             dataloader: torch.utils.data.DataLoader, \n",
    "             loss_fn: torch.nn.Module, \n",
    "             device: torch.device) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Evaluate the model on the test dataset.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The neural network model to evaluate.\n",
    "        dataloader (torch.utils.data.DataLoader): DataLoader for the test dataset.\n",
    "        loss_fn (torch.nn.Module): Loss function for evaluation.\n",
    "        device (torch.device): Device to run the model on (e.g., 'cuda' or 'cpu').\n",
    "\n",
    "    Returns:\n",
    "        Tuple[float, float]: Average test loss and accuracy (in percentage).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    accuracy = 0.0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for X, y in dataloader:\n",
    "            # Move data to device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            y_logits = model(X)\n",
    "            loss = loss_fn(y_logits, y)\n",
    "            \n",
    "            # Compute predictions and accuracy\n",
    "            y_pred = torch.softmax(y_logits, dim=1).argmax(dim=1)\n",
    "            # Move to CPU and convert to NumPy for sklearn\n",
    "            y_cpu, y_pred_cpu = y.cpu().detach().numpy(), y_pred.cpu().detach().numpy()\n",
    "            accuracy += accuracy_score(y_cpu, y_pred_cpu)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "\n",
    "    # Compute average loss and accuracy\n",
    "    test_loss /= len(dataloader)\n",
    "    accuracy = (accuracy / len(dataloader)) * 100\n",
    "\n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6750cb-cfa7-4af4-a201-129611c22d84",
   "metadata": {},
   "source": [
    "### Function for engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c134c406-5965-42d9-bc44-29f2d95251e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Dict, List\n",
    "\n",
    "def engine(model: torch.nn.Module, \n",
    "           train_dataloader: torch.utils.data.DataLoader,\n",
    "           test_dataloader: torch.utils.data.DataLoader, \n",
    "           loss_fn: torch.nn.Module, \n",
    "           optimizer: torch.optim.Optimizer, \n",
    "           device: torch.device, \n",
    "           epochs: int) -> Dict[str, List[float]]:\n",
    "    \"\"\"\n",
    "    Train and evaluate a PyTorch model over multiple epochs, tracking performance metrics.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The neural network model to train and evaluate.\n",
    "        train_dataloader (torch.utils.data.DataLoader): DataLoader for the training dataset.\n",
    "        test_dataloader (torch.utils.data.DataLoader): DataLoader for the test dataset.\n",
    "        loss_fn (torch.nn.Module): Loss function for training and evaluation.\n",
    "        optimizer (torch.optim.Optimizer): Optimizer for updating model parameters.\n",
    "        device (torch.device): Device to run the model on (e.g., 'cuda' or 'cpu').\n",
    "        epochs (int): Number of training epochs.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, List[float]]: Dictionary containing lists of epoch numbers, training losses,\n",
    "                                training accuracies, test losses, and test accuracies.\n",
    "    \"\"\"\n",
    "    # Initialize results dictionary\n",
    "    result = {\n",
    "        'epoch': [],\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'test_loss': [],\n",
    "        'test_acc': []\n",
    "    }\n",
    "\n",
    "    for i in range(epochs):\n",
    "        # Train for one epoch\n",
    "        train_loss, train_acc = train_set(\n",
    "            model=model,\n",
    "            dataloader=train_dataloader,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optimizer,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        # Evaluate on test set\n",
    "        test_loss, test_acc = test_set(\n",
    "            model=model,\n",
    "            dataloader=test_dataloader,\n",
    "            loss_fn=loss_fn,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        # Store metrics\n",
    "        result['epoch'].append(i + 1)\n",
    "        result['train_loss'].append(train_loss)\n",
    "        result['train_acc'].append(train_acc)\n",
    "        result['test_loss'].append(test_loss)\n",
    "        result['test_acc'].append(test_acc)\n",
    "\n",
    "        # Print progress\n",
    "        print(f\"Epoch {i + 1} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.2f}%\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bde61bc-c6b2-4595-9c2f-9b0ecac6f18b",
   "metadata": {},
   "source": [
    "### Function for save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6df0258f-0354-465e-a93f-b96ec69895c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "def save_model(path: Path, model: torch.nn.Module) -> None:\n",
    "    \"\"\"\n",
    "    Save the model's state dictionary to a specified file path.\n",
    "\n",
    "    Args:\n",
    "        path (Path): Directory path where the model will be saved.\n",
    "        model (torch.nn.Module): The PyTorch model to save.\n",
    "\n",
    "    Returns:\n",
    "        None: The function saves the model and prints a confirmation message.\n",
    "    \"\"\"\n",
    "    # Ensure the directory exists\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Define the file path\n",
    "    file_name = path / \"vit_model_on_food101.pth\"\n",
    "    \n",
    "    # Save the model's state dictionary\n",
    "    torch.save(obj=model.state_dict(), f=file_name)\n",
    "    \n",
    "    # Print confirmation\n",
    "    print(f\"The model has been saved successfully to {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d350c5a-8a0a-4207-b79f-293639be64d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
